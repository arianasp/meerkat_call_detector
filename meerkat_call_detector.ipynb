{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tlFkdWQOrEci"
   },
   "source": [
    "# **Meerkat Call Detection Framework**\n",
    "\n",
    "This notebook allows you to go through the full process of training a CNN on meerkat calls, running the CNN on new files to extract potential calls, and then evaluating the effectiveness using ROC curves. You can go through all steps or perform a subset of them, but first choose which files you will be using for training and testing.\n",
    "\n",
    "## Set parameters\n",
    "Here, you set up the parameters needed for the training and testing. Run the cell below before you run the rest of the notebook!\n",
    "\n",
    "**Directories**\n",
    "\n",
    "All directories need to be accessible from your Google Drive.\n",
    "\n",
    "*audio_dir*: This should contain 3 subfolders. 'calls' and 'noise' are folders where the call and noise snippets used for training are located. 'long_recordings' is where full audio files are\n",
    "\n",
    "*groundtruth_dir*: This is the directory containing csv files of labeled data\n",
    "\n",
    "*model_dir*: This directory contains fitted models\n",
    "\n",
    "*output_dir*: This is where the output (.pckl and .csv files) will be stored\n",
    "\n",
    "*code_dir*: Directory where code is stored\n",
    "\n",
    "**Files**\n",
    "\n",
    "*model_name*: file name for the output model, or for the model to load (in the case of using a pre-trained model)\n",
    "\n",
    "**Training parameters**\n",
    "\n",
    "*epochs*: number of epochs to train for\n",
    "\n",
    "*batch_size*: batch size of data to use\n",
    "\n",
    "*steps_per_epoch*: how many training steps per epoch\n",
    "\n",
    "**Prediction parameters**\n",
    "\n",
    "*audio_file*: name of audio file to run prediction on\n",
    "\n",
    "*t_start*: start time for predictions within audio file (sec)\n",
    "\n",
    "*t_end*: end time for predictions within audio file (sec)\n",
    "\n",
    "**Other parameters (probably don't need to change)**\n",
    "\n",
    "*samprate*: sample rate of audio file, should be 8000 for current code (code will likely not work with other sample rates!)\n",
    "\n",
    "*chunk_size*: number of seconds to read in each time wav is accessed directly\n",
    "\n",
    "*chunk_pad*: pad chunks of wavs on each end to avoid any issues - 1 sec is fine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 938
    },
    "colab_type": "code",
    "id": "9hlUy_XuqhSM",
    "outputId": "1e652e45-3c12-488f-b435-ed45ee088d00",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Training model --------\n",
      "Model name: cnn_20epoch__collar__orig_proportional_noaug_2dconv_20190531.h5\n",
      "Clips directory: /home/arianasp/meerkat_detector/clips\n",
      "CNN Dimension: 2\n",
      "Start time:\n",
      "2019-05-31 13:19:26.278611\n",
      "Creating new model\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 512, 128, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 512, 128, 32) 320         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 512, 128, 32) 0           conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 512, 128, 32) 9248        activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 512, 128, 32) 0           conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 512, 128, 32) 9248        activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 512, 128, 32) 0           conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_7 (AveragePoo (None, 256, 64, 32)  0           activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 256, 64, 32)  9248        average_pooling2d_7[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 256, 64, 32)  0           conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 256, 64, 32)  9248        activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 256, 64, 32)  0           conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 256, 64, 32)  9248        activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 256, 64, 32)  0           conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_8 (AveragePoo (None, 128, 32, 32)  0           activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 128, 32, 64)  18496       average_pooling2d_8[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 128, 32, 64)  0           conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 128, 32, 64)  36928       activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 128, 32, 64)  0           conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 128, 32, 64)  36928       activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 128, 32, 64)  0           conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_9 (AveragePoo (None, 64, 16, 64)   0           activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 64, 16, 96)   55392       average_pooling2d_9[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 64, 16, 96)   0           conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 64, 16, 96)   83040       activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 64, 16, 96)   0           conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 64, 16, 96)   83040       activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 64, 16, 96)   0           conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_10 (AveragePo (None, 32, 8, 96)    0           activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 32, 8, 128)   110720      average_pooling2d_10[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 32, 8, 128)   0           conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 32, 8, 128)   147584      activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 32, 8, 128)   0           conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 32, 8, 128)   147584      activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 32, 8, 128)   0           conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_11 (AveragePo (None, 16, 4, 128)   0           activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 16, 4, 160)   184480      average_pooling2d_11[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 16, 4, 160)   0           conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 16, 4, 160)   230560      activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 16, 4, 160)   0           conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 16, 4, 160)   230560      activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 16, 4, 160)   0           conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_12 (AveragePo (None, 8, 2, 160)    0           activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 8, 2, 160)    230560      average_pooling2d_12[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 8, 2, 160)    25760       average_pooling2d_12[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 8, 2, 160)    0           conv2d_50[0][0]                  \n",
      "                                                                 conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 8, 2, 160)    0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_7 (UpSampling2D)  (None, 16, 4, 160)   0           activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 16, 4, 128)   184448      up_sampling2d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 16, 4, 128)   16512       average_pooling2d_11[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 16, 4, 128)   0           conv2d_52[0][0]                  \n",
      "                                                                 conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 16, 4, 128)   0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_8 (UpSampling2D)  (None, 32, 8, 128)   0           activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 32, 8, 96)    110688      up_sampling2d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 32, 8, 96)    9312        average_pooling2d_10[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 32, 8, 96)    0           conv2d_54[0][0]                  \n",
      "                                                                 conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 32, 8, 96)    0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_9 (UpSampling2D)  (None, 64, 16, 96)   0           activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 64, 16, 64)   55360       up_sampling2d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 64, 16, 64)   4160        average_pooling2d_9[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 64, 16, 64)   0           conv2d_56[0][0]                  \n",
      "                                                                 conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 64, 16, 64)   0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_10 (UpSampling2D) (None, 128, 32, 64)  0           activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 128, 32, 32)  18464       up_sampling2d_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 128, 32, 32)  1056        average_pooling2d_8[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 128, 32, 32)  0           conv2d_58[0][0]                  \n",
      "                                                                 conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 128, 32, 32)  0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_11 (UpSampling2D) (None, 256, 64, 32)  0           activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 256, 64, 32)  9248        up_sampling2d_11[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 256, 64, 32)  1056        average_pooling2d_7[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 256, 64, 32)  0           conv2d_60[0][0]                  \n",
      "                                                                 conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 256, 64, 32)  0           add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_12 (UpSampling2D) (None, 512, 128, 32) 0           activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 512, 128, 1)  33          up_sampling2d_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "reshape_3 (Reshape)             (None, 512, 128)     0           conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 512, 1)       129         reshape_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 512, 1)       0           conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "reshape_4 (Reshape)             (None, 512, 1, 1)    0           activation_50[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 2,078,658\n",
      "Trainable params: 2,078,658\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 422s 422ms/step - loss: 0.1924\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 421s 421ms/step - loss: 0.1031\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 423s 423ms/step - loss: 0.1014\n",
      "Epoch 4/20\n",
      "1000/1000 [==============================] - 424s 424ms/step - loss: 0.0802\n",
      "Epoch 5/20\n",
      "1000/1000 [==============================] - 423s 423ms/step - loss: 0.0794\n",
      "Epoch 6/20\n",
      "1000/1000 [==============================] - 423s 423ms/step - loss: 0.0783\n",
      "Epoch 7/20\n",
      "1000/1000 [==============================] - 426s 426ms/step - loss: 0.0760\n",
      "Epoch 8/20\n",
      "1000/1000 [==============================] - 424s 424ms/step - loss: 0.0665\n",
      "Epoch 9/20\n",
      "1000/1000 [==============================] - 423s 423ms/step - loss: 0.0630\n",
      "Epoch 10/20\n",
      "1000/1000 [==============================] - 426s 426ms/step - loss: 0.0566\n",
      "Epoch 11/20\n",
      "1000/1000 [==============================] - 424s 424ms/step - loss: 0.0624\n",
      "Epoch 12/20\n",
      "1000/1000 [==============================] - 425s 425ms/step - loss: 0.0552\n",
      "Epoch 13/20\n",
      "1000/1000 [==============================] - 424s 424ms/step - loss: 0.0593\n",
      "Epoch 14/20\n",
      "1000/1000 [==============================] - 423s 423ms/step - loss: 0.0579\n",
      "Epoch 15/20\n",
      "1000/1000 [==============================] - 420s 420ms/step - loss: 0.0563\n",
      "Epoch 16/20\n",
      "1000/1000 [==============================] - 420s 420ms/step - loss: 0.0549\n",
      "Epoch 17/20\n",
      "1000/1000 [==============================] - 420s 420ms/step - loss: 0.0506\n",
      "Epoch 18/20\n",
      "1000/1000 [==============================] - 422s 422ms/step - loss: 0.0521\n",
      "Epoch 19/20\n",
      "1000/1000 [==============================] - 422s 422ms/step - loss: 0.0476\n",
      "Epoch 20/20\n",
      "1000/1000 [==============================] - 421s 421ms/step - loss: 0.0513\n",
      "End time:\n",
      "2019-05-31 15:40:25.001362\n",
      "Saving model as: cnn_20epoch__collar__orig_proportional_noaug_2dconv_20190531.h5\n",
      "-------- Done with training or loading model step --------\n",
      "-------- Running model on folder --------\n",
      "Folder path = /home/arianasp/meerkat_detector/data/full_recordings\n",
      "Found 46 audio files, running model on all of them\n",
      "Running predictions on file: \n",
      "/home/arianasp/meerkat_detector/data/full_recordings/HM_VCVM001_HMB_AUDIO_R08_ file_2_(2017_08_03-06_44_59)_ASWMUX221153_label.wav\n",
      "/home/arianasp/meerkat_detector/ground_truth/HM_VCVM001_HMB_AUDIO_R08_ file_2_(2017_08_03-06_44_59)_ASWMUX221153_label.csv\n",
      "<meerkat_call_detector_library.CallExtractionParams object at 0x7f6cfdf4c358>\n",
      "-------Running CNN model on new data-------\n",
      "model_path: /home/arianasp/meerkat_detector/models/cnn_20epoch__collar__orig_proportional_noaug_2dconv_20190531.h5\n",
      "wav_path: /home/arianasp/meerkat_detector/data/full_recordings/HM_VCVM001_HMB_AUDIO_R08_ file_2_(2017_08_03-06_44_59)_ASWMUX221153_label.wav\n",
      "samprate: 8000\n",
      "t_start: 3599.994\n",
      "t_end: 7357.024\n",
      "\n",
      "--------Generating predictions-------\n",
      "Start time:\n",
      "2019-05-31 15:40:25.647559\n",
      "End time:\n",
      "2019-05-31 15:42:21.244524\n",
      "\n",
      "-------Generating scores and extracting calls-------\n",
      "-------Saving output-------\n",
      "Done\n",
      "Running predictions on file: \n",
      "/home/arianasp/meerkat_detector/data/full_recordings/HM_VHMF001_HTB_AUDIO_R07_file_5_(2017_08_06-06_44_59)_ASWMUX221092_label.wav\n",
      "/home/arianasp/meerkat_detector/ground_truth/HM_VHMF001_HTB_AUDIO_R07_file_5_(2017_08_06-06_44_59)_ASWMUX221092_label.CSV\n",
      "<meerkat_call_detector_library.CallExtractionParams object at 0x7f6d12573a58>\n",
      "-------Running CNN model on new data-------\n",
      "model_path: /home/arianasp/meerkat_detector/models/cnn_20epoch__collar__orig_proportional_noaug_2dconv_20190531.h5\n",
      "wav_path: /home/arianasp/meerkat_detector/data/full_recordings/HM_VHMF001_HTB_AUDIO_R07_file_5_(2017_08_06-06_44_59)_ASWMUX221092_label.wav\n",
      "samprate: 8000\n",
      "t_start: 3600.015\n",
      "t_end: 7237.11\n",
      "\n",
      "--------Generating predictions-------\n",
      "Start time:\n",
      "2019-05-31 15:42:21.434593\n",
      "End time:\n",
      "2019-05-31 15:44:12.176579\n",
      "\n",
      "-------Generating scores and extracting calls-------\n",
      "-------Saving output-------\n",
      "Done\n",
      "Running predictions on file: \n",
      "/home/arianasp/meerkat_detector/data/full_recordings/HM_VLF206_SOUNDFOC_20170825_1_label_downsamp.wav\n",
      "/home/arianasp/meerkat_detector/ground_truth/HM_VLF206_SOUNDFOC_20170825_1_label.csv\n",
      "<meerkat_call_detector_library.CallExtractionParams object at 0x7f6c366fb240>\n",
      "Running predictions on file: \n",
      "/home/arianasp/meerkat_detector/data/full_recordings/HM_RT_R10_20170903-20170908_file_2_(2017_09_03-05_44_59)_ASWMUX221102_SS.wav\n",
      "/home/arianasp/meerkat_detector/ground_truth/HM_RT_R10_20170903-20170908_file_2_(2017_09_03-05_44_59)_ASWMUX221102_SS.csv\n",
      "<meerkat_call_detector_library.CallExtractionParams object at 0x7f6c372ca518>\n",
      "-------Running CNN model on new data-------\n",
      "model_path: /home/arianasp/meerkat_detector/models/cnn_20epoch__collar__orig_proportional_noaug_2dconv_20190531.h5\n",
      "wav_path: /home/arianasp/meerkat_detector/data/full_recordings/HM_RT_R10_20170903-20170908_file_2_(2017_09_03-05_44_59)_ASWMUX221102_SS.wav\n",
      "samprate: 8000\n",
      "t_start: 3600.0\n",
      "t_end: 7200.0\n",
      "\n",
      "--------Generating predictions-------\n",
      "Start time:\n",
      "2019-05-31 15:44:12.355277\n",
      "End time:\n",
      "2019-05-31 15:46:00.388110\n",
      "\n",
      "-------Generating scores and extracting calls-------\n",
      "-------Saving output-------\n",
      "Done\n",
      "Running predictions on file: \n",
      "/home/arianasp/meerkat_detector/data/full_recordings/HM_LT_R07_AUDIO_file_6_(2017_08_25-06_44_59)_ASWMUX221092_label.wav\n",
      "/home/arianasp/meerkat_detector/ground_truth/HM_LT_R07_AUDIO_file_6_(2017_08_25-06_44_59)_ASWMUX221092_label.csv\n",
      "<meerkat_call_detector_library.CallExtractionParams object at 0x7f6ced72d470>\n",
      "-------Running CNN model on new data-------\n",
      "model_path: /home/arianasp/meerkat_detector/models/cnn_20epoch__collar__orig_proportional_noaug_2dconv_20190531.h5\n",
      "wav_path: /home/arianasp/meerkat_detector/data/full_recordings/HM_LT_R07_AUDIO_file_6_(2017_08_25-06_44_59)_ASWMUX221092_label.wav\n",
      "samprate: 8000\n",
      "t_start: 3600.0\n",
      "t_end: 7319.122\n",
      "\n",
      "--------Generating predictions-------\n",
      "Start time:\n",
      "2019-05-31 15:46:00.566664\n",
      "End time:\n",
      "2019-05-31 15:47:54.189984\n",
      "\n",
      "-------Generating scores and extracting calls-------\n",
      "-------Saving output-------\n",
      "Done\n",
      "Running predictions on file: \n",
      "/home/arianasp/meerkat_detector/data/full_recordings/HM_VCVM001_AUDIO_file_5_(2017_08_06-06_44_59)_ASWMUX221153_label.wav\n",
      "/home/arianasp/meerkat_detector/ground_truth/HM_VCVM001_AUDIO_file_5_(2017_08_06-06_44_59)_ASWMUX221153_label.CSV\n",
      "<meerkat_call_detector_library.CallExtractionParams object at 0x7f6d12573a58>\n",
      "-------Running CNN model on new data-------\n",
      "model_path: /home/arianasp/meerkat_detector/models/cnn_20epoch__collar__orig_proportional_noaug_2dconv_20190531.h5\n",
      "wav_path: /home/arianasp/meerkat_detector/data/full_recordings/HM_VCVM001_AUDIO_file_5_(2017_08_06-06_44_59)_ASWMUX221153_label.wav\n",
      "samprate: 8000\n",
      "t_start: 3600.0\n",
      "t_end: 7519.989\n",
      "\n",
      "--------Generating predictions-------\n",
      "Start time:\n",
      "2019-05-31 15:47:54.375597\n",
      "End time:\n",
      "2019-05-31 15:49:52.899374\n",
      "\n",
      "-------Generating scores and extracting calls-------\n",
      "-------Saving output-------\n",
      "Done\n",
      "Running predictions on file: \n",
      "/home/arianasp/meerkat_detector/data/full_recordings/HM_HTB_R14_file_6_(2017_08_25-06_44_59)_ASWMUX221052_label.wav\n",
      "/home/arianasp/meerkat_detector/ground_truth/HM_HTB_R14_file_6_(2017_08_25-06_44_59)_ASWMUX221052_label.csv\n",
      "<meerkat_call_detector_library.CallExtractionParams object at 0x7f6c366e86a0>\n",
      "-------Running CNN model on new data-------\n",
      "model_path: /home/arianasp/meerkat_detector/models/cnn_20epoch__collar__orig_proportional_noaug_2dconv_20190531.h5\n",
      "wav_path: /home/arianasp/meerkat_detector/data/full_recordings/HM_HTB_R14_file_6_(2017_08_25-06_44_59)_ASWMUX221052_label.wav\n",
      "samprate: 8000\n",
      "t_start: 3600.0\n",
      "t_end: 7264.012\n",
      "\n",
      "--------Generating predictions-------\n",
      "Start time:\n",
      "2019-05-31 15:49:53.086119\n",
      "End time:\n",
      "2019-05-31 15:51:43.244319\n",
      "\n",
      "-------Generating scores and extracting calls-------\n",
      "-------Saving output-------\n",
      "Done\n",
      "Running predictions on file: \n",
      "/home/arianasp/meerkat_detector/data/full_recordings/HM_RT_R12_file_5_(2017_08_24-06_44_59)_ASWMUX221102_LABEL_RY.wav\n",
      "/home/arianasp/meerkat_detector/ground_truth/HM_RT_R12_file_5_(2017_08_24-06_44_59)_ASWMUX221102_LABEL_RY.csv\n",
      "<meerkat_call_detector_library.CallExtractionParams object at 0x7f6cfdf4c358>\n",
      "-------Running CNN model on new data-------\n",
      "model_path: /home/arianasp/meerkat_detector/models/cnn_20epoch__collar__orig_proportional_noaug_2dconv_20190531.h5\n",
      "wav_path: /home/arianasp/meerkat_detector/data/full_recordings/HM_RT_R12_file_5_(2017_08_24-06_44_59)_ASWMUX221102_LABEL_RY.wav\n",
      "samprate: 8000\n",
      "t_start: 3240.0\n",
      "t_end: 6840.0\n",
      "\n",
      "--------Generating predictions-------\n",
      "Start time:\n",
      "2019-05-31 15:51:43.413839\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End time:\n",
      "2019-05-31 15:53:30.172707\n",
      "\n",
      "-------Generating scores and extracting calls-------\n",
      "-------Saving output-------\n",
      "Done\n",
      "Running predictions on file: \n",
      "/home/arianasp/meerkat_detector/data/full_recordings/HM_HRT_R09_AUDIO_file_6_(2017_08_25-06_44_59)_ASWMUX221110_label.wav\n",
      "/home/arianasp/meerkat_detector/ground_truth/HM_HRT_R09_AUDIO_file_6_(2017_08_25-06_44_59)_ASWMUX221110_label.csv\n",
      "<meerkat_call_detector_library.CallExtractionParams object at 0x7f6c602a5240>\n",
      "-------Running CNN model on new data-------\n",
      "model_path: /home/arianasp/meerkat_detector/models/cnn_20epoch__collar__orig_proportional_noaug_2dconv_20190531.h5\n",
      "wav_path: /home/arianasp/meerkat_detector/data/full_recordings/HM_HRT_R09_AUDIO_file_6_(2017_08_25-06_44_59)_ASWMUX221110_label.wav\n",
      "samprate: 8000\n",
      "t_start: 3600.0\n",
      "t_end: 7325.0\n",
      "\n",
      "--------Generating predictions-------\n",
      "Start time:\n",
      "2019-05-31 15:53:30.341360\n"
     ]
    }
   ],
   "source": [
    "#TODO: Fix evaluation, need to match up file names due to 8000_LEFT extension\n",
    "\n",
    "#PARAMETERS - Modify parameters before running to change settings!\n",
    "#-------------------------------------------------------------------------------\n",
    "\n",
    "#---------TO CHANGE--------:\n",
    "\n",
    "#General\n",
    "use_pretrained_model = False #whether to load a pre-trained model (either to go to evaluation or to continue training with new data)\n",
    "train_model = True #whether or not to train model or skip straight to evaluation\n",
    "run_model_on_file = False\n",
    "run_model_on_folder = True\n",
    "run_model_on_specified_round = False\n",
    "\n",
    "specified_round = 2\n",
    "specified_model_name = None #defaults to None. use only if use_pretrained_model is True or if you want to specify the name of the model directly\n",
    "run_only_where_ground_truth_available = True #set to True to run only on parts of files where groundtruth labels are available\n",
    "evaluate_detections = True\n",
    "focal = False #whether to use focal recordings (or collar data if false)\n",
    "focal_megan = False\n",
    "\n",
    "foc_megan_dir = '/media/arianasp/Elements/Sound Files/Ari Examined files/A. Clean'\n",
    "ground_truth_path_test_megan = '/home/arianasp/meerkat_detector/labels_megan/focal_labels_test.csv'\n",
    "\n",
    "#Model fitting options (use only if train_model is True)\n",
    "epochs = 20 #Number of epochs to train for\n",
    "augment = False #whether to augment by overlaying noise (at different levels) on calls\n",
    "conv_dimension = 2\n",
    "\n",
    "#name of audio file (use only if run_model_on_file is True)\n",
    "#audio_file_to_predict = 'HM_PET_R11_20170903-20170908_file_2_(2017_09_03-05_44_59)_ASWMUX221163_SS.wav'\n",
    "audio_file_to_predict = 'OCS1451_VJXM100_L_1_6FEB2017_LEFT_8000.wav'\n",
    "#audio_file_to_predict = 'HM_VLF206_SOUNDFOC_20170903_LABEL_RY_downsamp.wav'\n",
    "\n",
    "#Name of audio folder for prediction (use only if run_model_on_folder is True)\n",
    "audio_folder = '/home/arianasp/meerkat_detector/data/full_recordings'\n",
    "\n",
    "#Probability of selecting each call type for training (call types given below). If None, choose calls with probability equal to their occurrence in the training data\n",
    "call_probs = None\n",
    "\n",
    "#---------TO LEAVE ALONE (PROBABLY)--------:\n",
    "\n",
    "#Main directory\n",
    "base_dir = '/home/arianasp/meerkat_detector' #base directory\n",
    "\n",
    "#Subdirectories\n",
    "audio_dir = base_dir + '/data/full_recordings'\n",
    "if focal_megan:\n",
    "    audio_dir = foc_megan_dir\n",
    "\n",
    "ground_truth_dir = base_dir + '/ground_truth'\n",
    "model_dir = base_dir + '/models'\n",
    "output_dir = base_dir + '/predictions'\n",
    "code_dir = base_dir + '/dev'\n",
    "if(focal):\n",
    "    clips_dir = base_dir + '/clips_foc'\n",
    "elif(focal_megan):\n",
    "    clips_dir = base_dir +'/clips_foc_megan_all'\n",
    "else:\n",
    "    clips_dir = base_dir + '/clips'\n",
    "eval_dir = base_dir + '/eval'\n",
    "\n",
    "#Training parameters\n",
    "batch_size = 100\n",
    "steps_per_epoch = 1000 #1000\n",
    "call_types = ['cc','sn','ld','mov','agg','alarm','soc','hyb','unk','oth']\n",
    "\n",
    "#Evaluation parameters\n",
    "boundary_thresh = 0.6\n",
    "n_points = 30\n",
    "pckl_paths = ['/home/arianasp/meerkat_detector/predictions/OCS1451_VJXM100_L_1_6FEB2017_LEFT_8000_label_cnn_10epoch__focalmeg__orig_proportional_noaug_2dconv_20190306_1-1094.7.pckl'] #NOTE: One can specify pckl_paths, but this is only useful when running evluation ALONE, otherwise anything specified here gets cleared\n",
    "\n",
    "#Other parameters\n",
    "samprate = 8000 \n",
    "chunk_size = 60 \n",
    "chunk_pad = 1 \n",
    "ml_plan_file = base_dir + '/docs/' + 'audio_labeling_plan_filenames.csv'\n",
    "learn_rate = 2e-5\n",
    "\n",
    "#SETUP\n",
    "#-------------------------------------------------------------------------------\n",
    "\n",
    "#import libraries\n",
    "import sys\n",
    "import os\n",
    "import wave\n",
    "import time\n",
    "import glob\n",
    "import audioread\n",
    "\n",
    "#Set path\n",
    "sys.path.append(code_dir)\n",
    "\n",
    "#Import call detector library\n",
    "from meerkat_call_detector_library import *\n",
    "\n",
    "#NEW MODEL CONSTRUCTION DEFINITIONS (TO MOVE LATER)\n",
    "#inputs: originally spectrogram or output of upper layer\n",
    "#filters: number of filters to use (arbitrary)\n",
    "#n_convs: number of consecutive convolutions to do\n",
    "#output will be time_dim(inputs)/2 x n_filters\n",
    "\n",
    "\n",
    "#Set up file names and paths\n",
    "aug_str = 'noaug'\n",
    "if(augment):\n",
    "    aug_str = 'aug'\n",
    "    \n",
    "dim_str = '_1dconv_'\n",
    "if(conv_dimension==2):\n",
    "    dim_str = '_2dconv_'\n",
    "    \n",
    "focal_str = '_collar_'\n",
    "if(focal):\n",
    "    focal_str = '_focal_'\n",
    "elif(focal_megan):\n",
    "    focal_str = '_focalmeg_'\n",
    "\n",
    "if(call_probs is not None):\n",
    "    call_probs_str = ''.join([str(s) + '_' for s in call_probs])\n",
    "else:\n",
    "    call_probs_str = 'proportional_'\n",
    "    \n",
    "pretrain_str = '_orig_'\n",
    "if(use_pretrained_model):\n",
    "    pretrain_str = '_pretrained_'\n",
    "\n",
    "#if model name was specified, use specified name here. otherwise construct name based on parameters.\n",
    "if(not(train_model)):\n",
    "    model_name = specified_model_name\n",
    "else:\n",
    "    model_name = 'cnn_' + str(epochs) + 'epoch_' +  focal_str + pretrain_str + call_probs_str + aug_str + dim_str + time.strftime('%Y%m%d') + '.h5'\n",
    "model_path = model_dir + '/' + model_name\n",
    "\n",
    "#create threshold range for evaluation\n",
    "thresh_range = np.linspace(boundary_thresh+.0001,.9,10)\n",
    "\n",
    "for i in range(2,n_points-9):\n",
    "    thresh_range = np.append(thresh_range,thresh_range[len(thresh_range)-1]+10**(-i)*9)\n",
    "    \n",
    "#TRAIN OR LOAD MODEL\n",
    "#-------------------------------------------------------------------------------\n",
    "        \n",
    "if(use_pretrained_model):\n",
    "\n",
    "    print(\"-------- Loading pretrained model --------\")\n",
    "    print('Model name: ' + specified_model_name)\n",
    "  \n",
    "    #Load pre-trained model\n",
    "    model = load_model(model_dir + '/' + specified_model_name)\n",
    "\n",
    "if(train_model):\n",
    "  \n",
    "    print(\"-------- Training model --------\")\n",
    "    print('Model name: ' + model_name)\n",
    "    print(\"Clips directory: \" + clips_dir)\n",
    "    print('CNN Dimension: ' + str(conv_dimension))\n",
    "    print('Start time:')\n",
    "    print(datetime.datetime.now())\n",
    "\n",
    "    if(not(use_pretrained_model)):\n",
    "        print('Creating new model')\n",
    "        #Construct model\n",
    "        if(conv_dimension==1):\n",
    "            model = construct_unet_model(lr=learn_rate)\n",
    "        else:\n",
    "            model = construct_unet_model_2d(lr=learn_rate)\n",
    "        model.summary()\n",
    "\n",
    "    #Fit model\n",
    "    model.fit_generator(data_generator(clips_dir = clips_dir,batch_size = batch_size, cnn_dim=conv_dimension), epochs=epochs, use_multiprocessing=True, workers=16, steps_per_epoch=steps_per_epoch)\n",
    "\n",
    "    print('End time:')\n",
    "    print(datetime.datetime.now())\n",
    "\n",
    "    #Save fitted model\n",
    "    print('Saving model as: ' + model_name)\n",
    "    model.save(filepath=model_dir + '/' + model_name) \n",
    "\n",
    "print(\"-------- Done with training or loading model step --------\")\n",
    "\n",
    "\n",
    "#RUN MODEL TO DETECT CALLS\n",
    "#-------------------------------------------------------------------------------\n",
    "#Extract probable calls from wav recording\n",
    "                    \n",
    "if(run_model_on_folder):\n",
    "    \n",
    "    print(\"-------- Running model on folder --------\")\n",
    "    print('Folder path = ' + audio_folder)\n",
    "    \n",
    "    #get all audio files in that folder (or subfolders of it, recursively)\n",
    "    audio_files = glob.glob(audio_folder + '/**/' + '*.wav',recursive=True)\n",
    "    \n",
    "    #print number of files found\n",
    "    print('Found ' + str(len(audio_files)) + ' audio files, running model on all of them')\n",
    "    \n",
    "if(run_model_on_specified_round):\n",
    "    \n",
    "    print(\"-------- Running model on specified round --------\")\n",
    "    print('Round = ' + str(specified_round))\n",
    "\n",
    "    ml_plan = pandas.read_csv(ml_plan_file)\n",
    "    files_to_run = ml_plan[(ml_plan['Round (0-1)'] == str(specified_round)) | (ml_plan['Round (1-2)'] == str(specified_round)) | (ml_plan['Round (2+)'] == str(specified_round))]\n",
    "    files_to_run = files_to_run['Audio filename'].tolist()\n",
    "\n",
    "    audio_files = list()\n",
    "\n",
    "    for f_idx in range(len(files_to_run)):\n",
    "        curr_file = glob.glob(base_dir + '/data/raw_data' + '/**/' + files_to_run[f_idx], recursive=True)[0]\n",
    "        audio_files.append(curr_file)\n",
    "\n",
    "    #print number of files found\n",
    "    print('Found ' + str(len(audio_files)) + ' audio files, running model on all of them')\n",
    "\n",
    "if(run_model_on_folder or run_model_on_specified_round):\n",
    "    \n",
    "    for i in range(len(audio_files)):\n",
    "        \n",
    "        audio_file = audio_files[i]\n",
    "        wav_path = audio_file\n",
    "        \n",
    "        print('Running predictions on file: ')\n",
    "        print(audio_file)\n",
    "        \n",
    "        #aud = wave.open(audio_file,'rb')\n",
    "        \n",
    "        #time bounds for extraction\n",
    "        if(run_only_where_ground_truth_available):\n",
    "            labels = get_ground_truth_labels(wav_name = os.path.basename(audio_file), ground_truth_dir = ground_truth_dir)\n",
    "            if(labels is None):\n",
    "                print('No ground truth data found - skipping this file')\n",
    "                continue\n",
    "            else:\n",
    "                [t_start, t_end] = get_start_end_time_labels(labels)\n",
    "        else:\n",
    "            t_start = 1\n",
    "            with audioread.audio_open(wav_path) as f:\n",
    "                t_end = f.duration - 1.5\n",
    "        \n",
    "        #start at least 1 sec in to avoid problems of wrong input size in next step\n",
    "        if(t_start < 1):\n",
    "            t_start = 1\n",
    "        \n",
    "        #Store parameters in extraction_params object\n",
    "        audio_name = os.path.basename(audio_file)\n",
    "        pckl_path = output_dir + '/' + audio_name[0:(len(audio_name)-4)] + \"_label_\" + model_name[0:(len(model_name)-3)] + '_' + str(t_start) + '-' + str(t_end) + \".pckl\"\n",
    "        \n",
    "        #Append to list of created pckl paths\n",
    "        pckl_paths.append(pckl_path)\n",
    "        \n",
    "        #if path to extraction results already exists, do not run. otherwise run.\n",
    "        if(not(os.path.exists(pckl_path))):\n",
    "            extraction_params = CallExtractionParams(model_path = model_path, wav_path = wav_path, pckl_path=pckl_path, samprate = samprate, t_start = t_start, t_end = t_end)\n",
    "            print(extraction_params)\n",
    "            \n",
    "            #if SOUNDFOC is in filename, this indicates a different type of sound file - don't run!\n",
    "            if(re.search('SOUNDFOC',audio_file)==None):\n",
    "                extract_scores(model, extraction_params)\n",
    "\n",
    "#Run model on a specific file\n",
    "if(run_model_on_file):\n",
    "    \n",
    "    print('--------Running model on specific file---------')\n",
    "\n",
    "    #create paths to prediction files (wav and pckl)\n",
    "    wav_path = audio_dir + '/' + audio_file_to_predict\n",
    "    \n",
    "    print(wav_path)\n",
    "    \n",
    "    #tibase_dir = '/home/arianasp/meerkat_detector'me bounds for extraction\n",
    "    if(run_only_where_ground_truth_available): #TODO: add option to find labeled portion and run only for this\n",
    "        labels = get_ground_truth_labels(wav_name = audio_file_to_predict, ground_truth_dir = ground_truth_dir)\n",
    "        if(labels is None):\n",
    "            print('No ground truth data found - set run_only_where_ground_truth_available to False to run on this file')\n",
    "            t_start = None\n",
    "        else:\n",
    "            [t_start, t_end] = get_start_end_time_labels(labels)\n",
    "            t_end = t_end - 1\n",
    "        #start at least 1 sec in to avoid problems with wrong matrix size in next step\n",
    "        if t_start < 1:\n",
    "            t_start = 1\n",
    "    else:\n",
    "        t_start = 1\n",
    "        with audioread.audio_open(wav_path) as f:\n",
    "            t_end = f.duration - 1.5\n",
    "        \n",
    "    if(t_start is not None):\n",
    "    \n",
    "        #create path to output file\n",
    "        pckl_path = output_dir + '/' + audio_file_to_predict[0:(len(audio_file_to_predict)-4)] + \"_label_\" + model_name[0:(len(model_name)-3)] + '_' + str(t_start) + '-' + str(t_end) + \".pckl\"\n",
    "    \n",
    "        pckl_paths = [pckl_path]\n",
    "        extraction_params = CallExtractionParams(model_path = model_path, wav_path = wav_path, pckl_path = pckl_path, samprate = samprate, t_start = t_start, t_end = t_end)\n",
    "        print(extraction_params.t_start)\n",
    "        print(extraction_params.t_end)\n",
    "        extract_scores(model, extraction_params)\n",
    "    \n",
    "#EVALUATE DETECTIONS\n",
    "#-------------------------------------------------------------------------------\n",
    "if(evaluate_detections & (pckl_paths is not None)):\n",
    "    \n",
    "    #for file_idx in range(len(pckl_files)):\n",
    "    for file_idx in range(len(pckl_paths)):\n",
    "\n",
    "        pckl_path = pckl_paths[file_idx]\n",
    "\n",
    "        if(focal_megan):\n",
    "            run_evaluation(pckl_path = pckl_path,thresh_range=thresh_range,save_dir =eval_dir,ground_truth_dir = None,call_types = call_types, verbose = False, ground_truth_path = ground_truth_path_test_megan, foc_megan = True)\n",
    "        else:\n",
    "            run_evaluation(pckl_path = pckl_path,thresh_range=thresh_range,save_dir =eval_dir,ground_truth_dir = ground_truth_dir,call_types = call_types, verbose = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "meerkat_call_detector.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
